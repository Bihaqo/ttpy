{
 "metadata": {
  "name": "",
  "signature": "sha256:c4eb3388476a03f289f7d0bba4043cdec8397db08b17bcd9b450c8ac54145d13"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Attempt-N for a new TT-cross"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I really like the basic symmetric two-dimensional algorithm. Basically, $U$ and $V$ produce a new vector one at a time.  \n",
      "The main question is: <span style=\"color:red\">can we generalize it to two dimensions?</span>  \n",
      "Suppose, for simplicity, a 3d-case, when we have $U_1$, $U_2$, and $U_3$. We start from a random rank-$1$ (say) tensor.  \n",
      "Then we can compute RL-maxvol in $U_3$ (and compute $\\widehat{U}_3^{-1} U_3$), and also store \n",
      "$J_3$. Then we can look on a $r_0 \\times (n r_0)$ matrix and produce $J_2$, index set of pairs $(i_2, i_3)$.  \n",
      "Now we can compute the actual tensor in the first mode. Then, we can compute **orthogonal complement** in this $U_{add}$. In order to do so, we have to take the first mode, take the submatrix of maximal volume there, and that is all we need. Then, we can compute $(i_1)_{add}$ -- how to extend the first index set. \n",
      "\n",
      "- Do we really need to have some initial index set? Can we just start from an empty vector? \n",
      "- Let us test it again in 2D"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy as sp\n",
      "import sys\n",
      "sys.path.append('/Users/ivan/work/python/ttpy/')\n",
      "import tt.maxvol.maxvol as maxvol\n",
      "n = 100\n",
      "r0 = 1\n",
      "\"\"\" Initialization \"\"\"\n",
      "u = np.random.randn(n, r0)\n",
      "v = np.zeros((n, 0))\n",
      "u, ru = np.linalg.qr(u)\n",
      "indu = maxvol(u)\n",
      "u = np.linalg.solve(u[indu, :].T, u.T).T\n",
      "indu_add = indu\n",
      "mat = [[i + j for j in xrange(n)] for i in xrange(n)]\n",
      "mat = np.array(mat)\n",
      "indv = np.empty((0,), dtype=np.int32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vadd = mat[indu_add, :]\n",
      "vadd = vadd.T\n",
      "\"\"\" Orthogonalize vadd to v \"\"\"\n",
      "comp_v = vadd - np.dot(v, vadd[indv, :])\n",
      "indv_add = maxvol(comp_v)\n",
      "v2 = np.linalg.solve(comp_v[indv_add, :].T, comp_v.T).T\n",
      "v1 = v - np.dot(v2, v[indv_add, :])\n",
      "v = np.hstack((v1, v2))\n",
      "indv = np.hstack((indv, indv_add)) \n",
      "\"\"\" Update u \"\"\"\n",
      "uadd = mat[:, indv_add]\n",
      "comp_u = uadd - np.dot(u, uadd[indu, :])\n",
      "\"\"\" Here we might stop \"\"\"\n",
      "er = np.linalg.norm(comp_u)\n",
      "print er\n",
      "indu_add = maxvol(comp_u)\n",
      "u2 = np.linalg.solve(comp_u[indu_add, :].T, comp_u.T).T\n",
      "u1 = u - np.dot(u2, u[indu_add, :])\n",
      "u = np.hstack((u1, u2))\n",
      "indu = np.hstack((indu, indu_add))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1627.73440756\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What we see, is that in the symmetric method there is no need to have some initialization for $V$. We start from a random $U$  \n",
      "vector and $V$ comes for free. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can check the same idea in the multidimensional case. We start from some $U_1, \\ldots, U_{d-1}$ and then $U_d$ comes for free,  \n",
      "and also tells us, what should be the first $J$ index from the right.  \n",
      "Now comes the crucial part: how can we work on the new (updated) $(d-1)$-th core?  \n",
      "For simplicity, consider 3D case.  \n",
      "Then, at first step the first core would be $n \\times 1$, the second -- $1 \\times n \\times 1$, and the last core,  \n",
      "compute from the index set $(i_1, i_2)$ that came from the left would be also $1 \\times n$.  \n",
      "In $1 \\times n$ core we compute the maximal element,  and this would be the first $i_3$ index.  \n",
      "In the **full** case, we will have to compute $n^2 \\times 1$ vector, however, we reduced it to $1 \\times n \\times 1$  \n",
      "core and update it from the right, making it $1 \\times n \\times 2$ (he-he).  \n",
      "Then we have to turn the order of this $1 \\times n \\times 2$ core.  \n",
      "I think I got it!! There is no need <span style=\"color:red\">to turn the order. </span>  \n",
      "In the right-to-left sweep we compute restriction indices **and** update the right ranks of the corresponding  \n",
      "$U$ cores.  Seems very reasonable.  \n",
      "So, the algorithm:\n",
      "\n",
      "- Initialize the cores to something random\n",
      "- Do left-right qr + maxvol\n",
      "- $V_d := A(I_d, i_d)$\n",
      "- Compute $J_d$ as the left maxvol of $V_d$\n",
      "\n",
      "There will be problems at the next iteration immediately.  \n",
      "**Idea**: Store the decompositions in two tensors instead of one.\n",
      "\n",
      "- Store left maxvol factors in $U$\n",
      "- Store right maxvol factors in $V$\n",
      "- First, fill $U$ at random\n",
      "- Then, fill $V_d$, using $V_d$ fill $V_{d-1}$\n",
      "- We can increase the rank between $U_{d-1}$ and $V_d$ as far as we can\n",
      "- Do we have to transfer anything between the k-th core and the next one? I think, yes\n",
      "\n",
      "How can we do the transfer in a right-to-left sweep? The matrix given is already in the \"UU^{-1}\" form,  \n",
      "so the question is, if we transfer that to the next core, this format will be preserved\n",
      "\n",
      "- We take $V_d$ and add rows ($V_{add}$, orthogonalize them, and \"enlarge\" the current; \n",
      "- This breaks the connection between $V_d$ and $V_{d-1}$ -- so, we have to increase the connecting rank just by enlarging the next core by zeros (so the product stays the same). This is only for **V** (or **U**) separatedly\n",
      "\n",
      "I have (quite elegantly) solved the problem with index extension. The individual basis is updated as  \n",
      "\\begin{equation}\n",
      "\\begin{pmatrix}\n",
      "U\\widehat{U}^{-1} - S\\widehat{S}^{-1} P (U\\widehat{U}^{-1}) & S\\widehat{S}^{-1}\n",
      "\\end{pmatrix},\n",
      "\\end{equation}\n",
      "where $P$ is a submatrix of the identity matrix that takes rows from ``indu_add`` from a matrix.  \n",
      "Then the following identity  \n",
      "\\begin{equation}\n",
      "\\begin{pmatrix}\n",
      "UU^{-1} - S\\widehat{S}^{-1} P (U\\widehat{U}^{-1}) & S\\widehat{S}^{-1} \n",
      "\\end{pmatrix} \\begin{pmatrix} I \\\\ P U\\widehat{U}^{-1} \\end{pmatrix} = U\\widehat{U}^{-1}\n",
      "\\end{equation}\n",
      "\n",
      "I have a storage question about storing the **already selected** indices. We **desperatedly need them**  \n",
      "for the fast update formula. In computations, it is a selection rule $r_i n_i \\rightarrow r_{i+1}$.  \n",
      "During the sweep, the rank $r_i$ can grow, does this change the indices? Let it be $r_i = 1$.  \n",
      "And it is a $4 \\times 2$ matrix with $0$ and $2$ as basis rows.  \n",
      "Then, the rank $r_i$ becomes equal to $2$.  \n",
      "The matrix is now $8 \\times 2$, with the first index $r_i$ being the fastest, so the original elements  \n",
      "come in **checkerboard** manner, and become $0$ (as before) and $4$. If we store pairs $(r_i, n_i)$ as a $r_{i+1} \\times 2$ array. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reshape(a, sz):\n",
      "    return np.reshape(a, sz, order='F')\n",
      "\n",
      "\n",
      "def mkron(a, b):\n",
      "    return np.kron(a, b)\n",
      "\n",
      "\n",
      "d = 3\n",
      "n = 3 * np.ones((d), np.int32)\n",
      "ru = np.zeros((d + 1), np.int32)\n",
      "ru[0] = 1\n",
      "ru[d] = 1\n",
      "r0 = 1\n",
      "ru[1:d] = r0\n",
      "rv = np.zeros((d + 1), np.int32)\n",
      "rv[0] = 1\n",
      "rv[d] = 1\n",
      "\"\"\" Initialization stuff \"\"\"\n",
      "U = [np.random.randn(ru[i], n[i], ru[i+1]) for i in xrange(d)]\n",
      "\n",
      "V = [ np.zeros((rv[i], n[i], rv[i+1])) for i in xrange(d)]\n",
      "I = [ np.empty(0, dtype=np.int32) for i in xrange(d+1)]\n",
      "J = [ np.empty(0, dtype=np.int32) for i in xrange(d+1)]\n",
      "maxvol_u = [ np.empty(0, dtype=np.int32) for i in xrange(d+1)]\n",
      "maxvol_v = [ np.empty(0, dtype=np.int32) for i in xrange(d+1)]\n",
      "indu_add = [ np.empty(0, dtype=np.int32) for i in xrange(d+1)]\n",
      "indv_add = [ np.empty(0, dtype=np.int32) for i in xrange(d+1)]\n",
      "\n",
      "rmat = np.ones((1, 1), dtype=np.float)\n",
      "for i in xrange(d-1):\n",
      "    cr = U[i]\n",
      "    cr = np.tensordot(rmat, cr, 1)\n",
      "    cr = reshape(cr, (ru[i] * n[i], -1))\n",
      "    u, rmat = np.linalg.qr(cr)\n",
      "    indu_loc = maxvol(u)\n",
      "    rmat = np.dot(u[indu_loc, :], rmat)\n",
      "    maxvol_u[i] = indu_loc.copy()\n",
      "    u = np.linalg.solve(u[indu_loc, :].T, u.T).T\n",
      "    U[i] = reshape(u, (ru[i], n[i], ru[i+1]))\n",
      "    w1 = mkron(np.ones((n[i], 1), dtype=np.int32), I[i])\n",
      "    w2 = mkron(reshape(np.arange(n[i], dtype=np.int32),(-1, 1)), np.ones((ru[i], 1), dtype=np.int32))\n",
      "    I[i + 1] = np.hstack((w1, w2))\n",
      "    I[i + 1] = reshape(I[i + 1], (ru[i] * n[i], -1))\n",
      "    I[i + 1] = I[i + 1][indu_loc, :]\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Main cycle \"\"\"\n",
      "def myfun(x):\n",
      "    return (x.sum(axis=1))\n",
      "    #return np.ones(x.shape[0])\n",
      "\n",
      "for i in xrange(d-1, 0, -1):\n",
      "    \"\"\" Form full index for vadd \"\"\" \n",
      "    if np.size(I[i]) == 0:\n",
      "        w1 = np.zeros((ru[i] * n[i] * rv[i + 1], 0))\n",
      "    else:\n",
      "        w1 = mkron(np.ones((n[i] * rv[i + 1], 1)), I[i])\n",
      "    w2 = mkron(mkron(np.ones((rv[i + 1], 1)), reshape(np.arange(n[i]), (-1, 1))), np.ones((ru[i], 1)))      \n",
      "    if np.size(J[i + 1]) == 0:\n",
      "        w3 = np.zeros((ru[i] * n[i] * rv[i + 1], 0))\n",
      "    else:\n",
      "        w3 = mkron(J[i + 1], np.ones((ru[i] * n[i], 1)))\n",
      "    \n",
      "    Jcur = np.hstack((w1, w2, w3))\n",
      "    vadd = myfun(Jcur)\n",
      "    vadd = reshape(vadd, (-1, n[i] * rv[i + 1]))\n",
      "    vadd = vadd.T\n",
      "    v = V[i]\n",
      "    v = reshape(v, (rv[i], n[i] * rv[i+1]))\n",
      "    v = v.T\n",
      "    \n",
      "    radd = vadd.shape[1]\n",
      "    vu = vadd[indv, :]\n",
      "    rmat = np.hstack((np.eye(rv[i]), vu))\n",
      "    rv[i] = rv[i] + radd\n",
      "    indv = maxvol_v[i]\n",
      "    comp_v = vadd - np.dot(v, vu)\n",
      "    ind_add = maxvol(comp_v)\n",
      "    v2 = np.linalg.solve(comp_v[ind_add, :].T, comp_v.T).T\n",
      "    v1 = v - np.dot(v2, v[ind_add, :])\n",
      "    v = np.hstack((v1, v2))\n",
      "    v = reshape(v, (n[i] * rv[i+1], rv[i]))\n",
      "    v = v.T\n",
      "    V[i] = reshape(v, (rv[i], n[i], rv[i+1])) #In fact we should compute the Schur complement to old V\n",
      "    if rmat.shape[0] > 0:\n",
      "        V[i-1] = np.tensordot(V[i-1], rmat, 1)\n",
      "    \n",
      "    w1 = mkron(np.ones((rv[i + 1], 1)), reshape(np.arange(n[i]),(-1, 1)))\n",
      "    if np.size(J[i + 1]) == 0:\n",
      "        w2 = np.zeros((n[i] * rv[i + 1], 0))\n",
      "    else:\n",
      "        w2 = mkron(J[i + 1], np.ones((n[i], 1)))\n",
      "    J[i] = np.hstack((w1, w2))\n",
      "    J[i] = reshape(J[i], (n[i] * rv[i + 1], -1))\n",
      "    J[i] = J[i][ind_add, :] #Now J contains \"the additional\" index\n",
      "    #Truncated extended index\n",
      "    \n",
      "    \n",
      "    \n",
      "    #Using the new index, we can update the next U core\n",
      "    u = U[i - 1]\n",
      "    if np.size(I[i-1]) == 0:\n",
      "        w1 = np.zeros((ru[i-1] * n[i-1] * rv[i], 0))\n",
      "    else:\n",
      "        w1 = mkron(np.ones((n[i-1] * rv[i], 1)), I[i-1])\n",
      "    w2 = mkron(mkron(np.ones((rv[i], 1)), reshape(np.arange(n[i-1]), (-1, 1))), np.ones((ru[i-1], 1)))      \n",
      "    if np.size(J[i]) == 0:\n",
      "        w3 = np.zeros((ru[i-1] * n[i-1] * rv[i], 0))\n",
      "    else:\n",
      "        w3 = mkron(J[i], np.ones((ru[i-1] * n[i-1], 1)))\n",
      "    Jadd =  np.hstack((w1, w2, w3))\n",
      "    uadd = myfun(Jadd)\n",
      "    u = reshape(u, (-1, ru[i]))\n",
      "    us = u\n",
      "    uadd = reshape(uadd, (u.shape[0], -1))\n",
      "    indu = maxvol_u[i-1]\n",
      "    comp_u = uadd - np.dot(u, uadd[indu, :])\n",
      "    comp_u, tmp = np.linalg.qr(comp_u)\n",
      "    ind_add = maxvol(comp_u)\n",
      "    u2 = np.linalg.solve(comp_u[ind_add, :].T, comp_u.T).T\n",
      "    u1 = u - np.dot(u2, u[ind_add, :])\n",
      "    uv = u[ind_add, :] #Auxiliary stuff\n",
      "    u = np.hstack((u1, u2))\n",
      "    radd = comp_u.shape[1]\n",
      "    rmat = np.vstack((np.eye(ru[i]), uv)) #Correction of the product\n",
      "    ru[i] = ru[i] + radd\n",
      "    U[i-1] = reshape(u, (ru[i-1], n[i-1], ru[i]))\n",
      "    #print reshape(np.tensordot(us, U[i], 1), (9, -1))\n",
      "    U[i] = np.tensordot(rmat, U[i], 1)\n",
      "    #U[i] = np.concatenate((U[i], np.zeros((radd, n[i], ru[i+1]))), axis=0)\n",
      "    #print 'and', reshape(np.tensordot(U[i-1], U[i], 1), (9, -1))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "index 99 is out of bounds for axis 0 with size 3",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-11-95bd8596a834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mradd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvadd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mvu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvadd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mrmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mrv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mradd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: index 99 is out of bounds for axis 0 with size 3"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0, 1)\n"
       ]
      }
     ],
     "prompt_number": 570
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = d - 1\n",
      "w1 = mkron(np.ones((n[i] * r[i + 1], 1)), I[i].T)\n",
      "w2 = mkron(mkron(np.ones((r[i + 1], 1)), reshape(np.arange(n[i]), (-1, 1))), np.ones((r[i], 1)))      \n",
      "print w2.shape\n",
      "print w1.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(4, 1)\n",
        "(6, 2)\n"
       ]
      }
     ],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mkron(np.ones((n[i] * r[i+1], 1)), I[i].T).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 177,
       "text": [
        "(6, 2)"
       ]
      }
     ],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print w2.shape\n",
      "print w1.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(4, 1)\n",
        "(4, 3)\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}